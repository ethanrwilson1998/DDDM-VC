{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# append top level dir to our path\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import utils\n",
    "from data_loader import MelSpectrogramFixed\n",
    "from inference import get_yaapt_f0, load_audio\n",
    "from model.vc_dddm_mixup import DDDM, Wav2vec2\n",
    "from model_f0_vqvae import Quantizer\n",
    "from vocoder.hifigan import HiFi\n",
    "\n",
    "mel_fn, w2v, f0_quantizer, model, net_v = None, None, None, None, None\n",
    "\n",
    "\n",
    "def _get_speaker_embedding(a):\n",
    "    global mel_fn, w2v, f0_quantizer, model, net_v\n",
    "\n",
    "    if mel_fn is None:\n",
    "        mel_fn = MelSpectrogramFixed(\n",
    "            sample_rate=hps.data.sampling_rate,\n",
    "            n_fft=hps.data.filter_length,\n",
    "            win_length=hps.data.win_length,\n",
    "            hop_length=hps.data.hop_length,\n",
    "            f_min=hps.data.mel_fmin,\n",
    "            f_max=hps.data.mel_fmax,\n",
    "            n_mels=hps.data.n_mel_channels,\n",
    "            window_fn=torch.hann_window,\n",
    "        ).cuda()\n",
    "\n",
    "    if w2v is None:\n",
    "        # Load pre-trained w2v (XLS-R)\n",
    "        w2v = Wav2vec2().cuda()\n",
    "\n",
    "    if f0_quantizer is None:\n",
    "        # Load model\n",
    "        f0_quantizer = Quantizer(hps).cuda()\n",
    "        utils.load_checkpoint(a.ckpt_f0_vqvae, f0_quantizer)\n",
    "        f0_quantizer.eval()\n",
    "\n",
    "    if model is None:\n",
    "        model = DDDM(\n",
    "            hps.data.n_mel_channels,\n",
    "            hps.diffusion.spk_dim,\n",
    "            hps.diffusion.dec_dim,\n",
    "            hps.diffusion.beta_min,\n",
    "            hps.diffusion.beta_max,\n",
    "            hps,\n",
    "        ).cuda()\n",
    "        utils.load_checkpoint(a.ckpt_model, model, None)\n",
    "        model.eval()\n",
    "\n",
    "    if net_v is None:\n",
    "        # Load vocoder\n",
    "        net_v = HiFi(\n",
    "            hps.data.n_mel_channels,\n",
    "            hps.train.segment_size // hps.data.hop_length,\n",
    "            **hps.model,\n",
    "        ).cuda()\n",
    "        utils.load_checkpoint(a.ckpt_voc, net_v, None)\n",
    "        net_v.eval().dec.remove_weight_norm()\n",
    "\n",
    "    # Convert audio\n",
    "    # print(\">> Converting each utterance...\")\n",
    "    src_name = os.path.splitext(os.path.basename(a.src_path))[0]\n",
    "    audio = load_audio(a.src_path)\n",
    "\n",
    "    src_mel = mel_fn(audio.cuda())\n",
    "    src_length = torch.LongTensor([src_mel.size(-1)]).cuda()\n",
    "    w2v_x = w2v(F.pad(audio, (40, 40), \"reflect\").cuda())\n",
    "\n",
    "    try:\n",
    "        f0 = get_yaapt_f0(audio.numpy())\n",
    "    except:\n",
    "        f0 = np.zeros((1, audio.shape[-1] // 80), dtype=np.float32)\n",
    "\n",
    "    ii = f0 != 0\n",
    "    f0[ii] = (f0[ii] - f0[ii].mean()) / f0[ii].std()\n",
    "    f0 = torch.FloatTensor(f0).cuda()\n",
    "    f0_code = f0_quantizer.code_extraction(f0)\n",
    "\n",
    "    trg_name = os.path.splitext(os.path.basename(a.trg_path))[0]\n",
    "    trg_audio = load_audio(a.trg_path)\n",
    "\n",
    "    trg_mel = mel_fn(trg_audio.cuda())\n",
    "    trg_length = torch.LongTensor([trg_mel.size(-1)]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        c = model.encode_speaker(\n",
    "            w2v_x,\n",
    "            f0_code,\n",
    "            src_length,\n",
    "            trg_mel,\n",
    "            trg_length,\n",
    "        )\n",
    "        return c.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotmap import DotMap\n",
    "\n",
    "\n",
    "def get_speaker_embedding(path_to_wav):\n",
    "    global hps, device, a\n",
    "    a = DotMap()\n",
    "    a.src_path = path_to_wav\n",
    "    a.trg_path = path_to_wav\n",
    "    a.ckpt_model = \".././ckpt/model_base.pth\"\n",
    "    a.ckpt_voc = \".././vocoder/voc_ckpt.pth\"\n",
    "    a.ckpt_f0_vqvae = \".././f0_vqvae/f0_vqvae.pth\"\n",
    "    a.t = 6\n",
    "    config = os.path.join(os.path.split(a.ckpt_model)[0], \"config.json\")\n",
    "    hps = utils.get_hparams_from_file(config)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return _get_speaker_embedding(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4882 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/wav2vec2-xls-r-300m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "INFO:root:Loaded checkpoint '.././f0_vqvae/f0_vqvae.pth' (iteration 77)\n",
      "INFO:root:Loaded checkpoint '.././ckpt/model_base.pth' (iteration 223)\n",
      "INFO:root:Loaded checkpoint '.././vocoder/voc_ckpt.pth' (iteration 1169)\n",
      "Removing weight norm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1823/4882 [50:58<1:19:38,  1.56s/it] c:\\Users\\ethanwilson\\Miniconda3\\envs\\DDDM-VC\\lib\\site-packages\\amfm_decompy\\pYAAPT.py:970: RuntimeWarning: invalid value encountered in divide\n",
      "  phi[lag_min:lag_max] = formula_nume/np.sqrt(formula_denom)\n",
      "100%|██████████| 4882/4882 [2:05:51<00:00,  1.55s/it]  \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import tqdm\n",
    "\n",
    "for p in tqdm.tqdm(glob.glob(\"D://vox1_test_wav/**/*.wav\", recursive=True)):\n",
    "    folders = p.split(os.sep)\n",
    "    speaker_id = folders[-3]\n",
    "    clip_id = folders[-2]\n",
    "    utterance_id = folders[-1]\n",
    "    emb = get_speaker_embedding(p)\n",
    "    speaker_embeddings.append(\n",
    "        {\n",
    "            \"speaker_id\": speaker_id,\n",
    "            \"clip_id\": clip_id,\n",
    "            \"utterance_id\": utterance_id,\n",
    "            \"embedding\": emb,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00001.wav</td>\n",
       "      <td>[[[-0.9422593], [-0.37463865], [0.19461837], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00002.wav</td>\n",
       "      <td>[[[-1.4136827], [-0.7891733], [0.3994071], [0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00003.wav</td>\n",
       "      <td>[[[-1.1209184], [-0.8950034], [1.3301648], [0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00004.wav</td>\n",
       "      <td>[[[-0.57233125], [-0.1521129], [0.46998602], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00005.wav</td>\n",
       "      <td>[[[-0.7774991], [-0.42959046], [0.93772507], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00004.wav</td>\n",
       "      <td>[[[-0.2039178], [1.0564528], [-0.015266762], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00005.wav</td>\n",
       "      <td>[[[-0.6076309], [0.59529996], [0.37479544], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00006.wav</td>\n",
       "      <td>[[[-0.24143918], [-0.19603784], [-0.43727106],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00007.wav</td>\n",
       "      <td>[[[-0.22903721], [-0.55159664], [0.6781072], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4881</th>\n",
       "      <td>id10270</td>\n",
       "      <td>5r0dWxy17C8</td>\n",
       "      <td>00008.wav</td>\n",
       "      <td>[[[-1.0417352], [0.6495084], [-0.77679706], [0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4882 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker_id      clip_id utterance_id  \\\n",
       "0       id10270  5r0dWxy17C8    00001.wav   \n",
       "1       id10270  5r0dWxy17C8    00002.wav   \n",
       "2       id10270  5r0dWxy17C8    00003.wav   \n",
       "3       id10270  5r0dWxy17C8    00004.wav   \n",
       "4       id10270  5r0dWxy17C8    00005.wav   \n",
       "...         ...          ...          ...   \n",
       "4877    id10270  5r0dWxy17C8    00004.wav   \n",
       "4878    id10270  5r0dWxy17C8    00005.wav   \n",
       "4879    id10270  5r0dWxy17C8    00006.wav   \n",
       "4880    id10270  5r0dWxy17C8    00007.wav   \n",
       "4881    id10270  5r0dWxy17C8    00008.wav   \n",
       "\n",
       "                                              embedding  \n",
       "0     [[[-0.9422593], [-0.37463865], [0.19461837], [...  \n",
       "1     [[[-1.4136827], [-0.7891733], [0.3994071], [0....  \n",
       "2     [[[-1.1209184], [-0.8950034], [1.3301648], [0....  \n",
       "3     [[[-0.57233125], [-0.1521129], [0.46998602], [...  \n",
       "4     [[[-0.7774991], [-0.42959046], [0.93772507], [...  \n",
       "...                                                 ...  \n",
       "4877  [[[-0.2039178], [1.0564528], [-0.015266762], [...  \n",
       "4878  [[[-0.6076309], [0.59529996], [0.37479544], [-...  \n",
       "4879  [[[-0.24143918], [-0.19603784], [-0.43727106],...  \n",
       "4880  [[[-0.22903721], [-0.55159664], [0.6781072], [...  \n",
       "4881  [[[-1.0417352], [0.6495084], [-0.77679706], [0...  \n",
       "\n",
       "[4882 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(len(speaker_embeddings))\n",
    "df = pd.DataFrame(speaker_embeddings)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"speaker_embeddings.pickle\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4882it [24:05,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity=24.855695724487305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sensitivity = 0\n",
    "\n",
    "for i, row1 in tqdm.tqdm(df.iterrows()):\n",
    "    for j, row2 in df.iterrows():\n",
    "        if row1[\"speaker_id\"] == row2[\"speaker_id\"]:\n",
    "            continue\n",
    "\n",
    "        emb1 = np.asarray(row1[\"embedding\"]).squeeze()\n",
    "        emb2 = np.asarray(row2[\"embedding\"]).squeeze()\n",
    "\n",
    "        dist = np.linalg.norm(emb1 - emb2)\n",
    "        if dist > sensitivity:\n",
    "            sensitivity = dist\n",
    "\n",
    "print(f\"sensitivity={sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"voxceleb1_sensitivity.txt\", \"w\") as file:\n",
    "    file.write(f\"sensitivity={sensitivity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDDM-VC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
