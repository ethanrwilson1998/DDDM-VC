{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# append top level dir to our path\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ethanwilson\\Miniconda3\\envs\\DDDM-VC\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|          | 0/4874 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/wav2vec2-xls-r-300m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "INFO:root:Loaded checkpoint '../f0_vqvae/f0_vqvae.pth' (iteration 77)\n",
      "INFO:root:Loaded checkpoint '../ckpt/model_base.pth' (iteration 223)\n",
      "INFO:root:Loaded checkpoint '../vocoder/voc_ckpt.pth' (iteration 1169)\n",
      "Removing weight norm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 41/4874 [01:20<2:13:37,  1.66s/it]d:\\github\\DDDM-VC\\notebooks\\..\\inference.py:119: RuntimeWarning: Mean of empty slice.\n",
      "  f0[ii] = (f0[ii] - f0[ii].mean()) / f0[ii].std()\n",
      "c:\\Users\\ethanwilson\\Miniconda3\\envs\\DDDM-VC\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\ethanwilson\\Miniconda3\\envs\\DDDM-VC\\lib\\site-packages\\numpy\\core\\_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\ethanwilson\\Miniconda3\\envs\\DDDM-VC\\lib\\site-packages\\numpy\\core\\_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "c:\\Users\\ethanwilson\\Miniconda3\\envs\\DDDM-VC\\lib\\site-packages\\numpy\\core\\_methods.py:257: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  1%|          | 41/4874 [01:21<2:40:24,  1.99s/it]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Expected (1, 1, 1456) got torch.Size([1, 1456])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m]:\n\u001b[0;32m     15\u001b[0m     a\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m=\u001b[39m eps\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\github\\DDDM-VC\\notebooks\\..\\inference_batch.py:31\u001b[0m, in \u001b[0;36mprocess_folder\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m     27\u001b[0m         a\u001b[38;5;241m.\u001b[39mtrg_path \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     28\u001b[0m             clip  \u001b[38;5;66;03m# Since we are processing per participant, keep trg_path same\u001b[39;00m\n\u001b[0;32m     29\u001b[0m         )\n\u001b[0;32m     30\u001b[0m     a\u001b[38;5;241m.\u001b[39moutput_path \u001b[38;5;241m=\u001b[39m new_clip\n\u001b[1;32m---> 31\u001b[0m     \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>> Processing Complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\github\\DDDM-VC\\notebooks\\..\\inference.py:121\u001b[0m, in \u001b[0;36minference\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    119\u001b[0m f0[ii] \u001b[38;5;241m=\u001b[39m (f0[ii] \u001b[38;5;241m-\u001b[39m f0[ii]\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m/\u001b[39m f0[ii]\u001b[38;5;241m.\u001b[39mstd() \n\u001b[0;32m    120\u001b[0m f0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(f0)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m--> 121\u001b[0m f0_code \u001b[38;5;241m=\u001b[39m \u001b[43mf0_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m trg_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(a\u001b[38;5;241m.\u001b[39mtrg_path))[\u001b[38;5;241m0\u001b[39m] \n\u001b[0;32m    124\u001b[0m trg_audio \u001b[38;5;241m=\u001b[39m load_audio(a\u001b[38;5;241m.\u001b[39mtrg_path)    \n",
      "File \u001b[1;32mc:\\Users\\ethanwilson\\Miniconda3\\envs\\DDDM-VC\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\github\\DDDM-VC\\notebooks\\..\\model_f0_vqvae.py:24\u001b[0m, in \u001b[0;36mQuantizer.code_extraction\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcode_extraction\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     f0_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     f0_h \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m f0_h]\n\u001b[0;32m     26\u001b[0m     zs, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvq(f0_h)\n",
      "File \u001b[1;32mc:\\Users\\ethanwilson\\Miniconda3\\envs\\DDDM-VC\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\github\\DDDM-VC\\notebooks\\..\\modules_vqvae\\jukebox.py:116\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    114\u001b[0m N, T \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    115\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_emb_width\n\u001b[1;32m--> 116\u001b[0m \u001b[43massert_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m xs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# 64, 32, ...\u001b[39;00m\n",
      "File \u001b[1;32md:\\github\\DDDM-VC\\notebooks\\..\\modules_vqvae\\jukebox.py:9\u001b[0m, in \u001b[0;36massert_shape\u001b[1;34m(x, exp_shape)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_shape\u001b[39m(x, exp_shape):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m exp_shape, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Expected (1, 1, 1456) got torch.Size([1, 1456])"
     ]
    }
   ],
   "source": [
    "from dotmap import DotMap\n",
    "\n",
    "from inference_batch import process_folder\n",
    "\n",
    "a = DotMap()\n",
    "a.audio_folder = \"D:/vox1_test_wav\"\n",
    "a.ckpt_model = \"../ckpt/model_base.pth\"\n",
    "a.ckpt_voc = \"../vocoder/voc_ckpt.pth\"\n",
    "a.ckpt_f0_vqvae = \"../f0_vqvae/f0_vqvae.pth\"\n",
    "a.time_step = 6\n",
    "a.method = \"IdentityDP\"\n",
    "a.theta = 0\n",
    "\n",
    "for eps in [1, 10, 50, 100, 200]:\n",
    "    a.epsilon = eps\n",
    "\n",
    "    process_folder(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDDM-VC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
